# 唯品会 2018 校招数据挖掘、机器学习笔试题（A 卷）

## 1

（数据结构与算法）列举至少 2 种排序算法（如快排），并写出实现代码

你的答案

本题知识点

数据挖掘工程师 算法工程师 唯品会 2018

讨论

[woooooody](https://www.nowcoder.com/profile/4384903)

```cpp

	def quick_sort(num, left, right):

	key =num[0]

	low =left

	high =right

	while left<right:

	while left<right and key<=num[right]:

	right-=1

	num[left] =num[right]

	while left<right and key>num[left]:

	left -=1

	num[right] =num[left]

	num[right] =key

	quick_sort(sum, low, left-1)

	quick_sort(sum, left+1, high)

	return num

	def merge_sort(num):

	if len(num)<=1: return num

	center =len(num)//2

	left =merge_sort(num[:center])

	right =merge_sort(num[center:])

	return merge(left, right)

	def merge(num1, num2):

	i ,j =0, 0

	result =[]

	while i<len(num1) and j<len(num2):

	if num1[i]<num2[j]:

	result.append(num1[i])

	i +=1

	else:

	result.append(num2[j])

	j +=1

	result +=num1[i:]

	result +=num2[j:]

	return result

	if__name__ =="__main__":

	num1 =input()

	num2 =input()

	num1 =quick_sort(num1, 0,len(num1)-1)

	num2 =merge_sort(num2)

	print(num1)

	print(num2)

```

编辑于 2019-07-22 11:13:52

* * *

[大厂秋招必过！](https://www.nowcoder.com/profile/934453073)

翻《数据挖掘》课本

发表于 2021-09-24 13:45:21

* * *

[12313242](https://www.nowcoder.com/profile/281228597)

1.冒泡排序

| 1234567891011 | def bubbleSort(numlist):    N = 0    key = True    while key and N < len(numlist):        key = False        for i in range(len(numlist)-N):            if numlist[i]>numlist[i+1]:                numlist[i],numlits[i+1] = numlist[i+1],numlist[i]                N = N + 1                key  = True    returnnumlist |

2.插入排序

| 1234567 | def insertionSort(numlist):    for i in rang(1,len(numlist)):        N = 0        while i> N and numlist[i-N]<numlist[i-N-1]:            numlist[i-N], numlist[i-N-1] = numlist[i-N-1],numlist[i-N]            N = N + 1    return numlist |

发表于 2020-09-18 15:14:49

* * *

## 2

（数据结构与算法）现有 N 个数，找出其中第 M 大的数，这里的 N 远大于 M。请说明算法思路、复杂度

你的答案

本题知识点

数据挖掘工程师 算法工程师 唯品会 2018

讨论

[一吻以谢天下](https://www.nowcoder.com/profile/245743)

建立一个容量为 M 的小根堆，遍历这 N 个元素，当前元素如果大于堆顶元素就删除堆顶元素加入此元素，这样操作后的堆容量还是 M，遍历完成依次取出堆顶元素，取到的最后一个元素就是所求。-- NORMAL --因为需要的空间只是容量为 M 的堆，所以空间复杂度为 O(M)首先建立容量为 M 的堆得时间复杂对为 O(N)遍历到一个元素时，可能插入，也可能不插入，如果每次都插入，也就是最坏情况，插入一个元素的时间复杂度为 O(log(M))，插入 N 个元素的时间复杂度也就是 O(N*log(M))。最后取元素的时间复杂度为 M*log(M)所以最坏时间复杂度为 O(M+N*log(M))=O(N*log(M))。

发表于 2018-03-03 20:32:24

* * *

[Spongebobmay](https://www.nowcoder.com/profile/7009754)

```cpp
def sink(heap,k,heapsize):
    while 2*k+1<=heapsize:
         j = 2*k+1
          if j<=heapsize and heap[j]<heap[j+1]:
              j++
          if heap[k]>=heap[j]:
              break
          heap[k],heap[j]=heap[j],heap[k]
          k=j
def heapsort(heap):
    N = len(heap)
    for i in xrange(N/2-1,-1,-1):
        sink(heap,i,N)
    while N>1:
        heap[0],heap[N--]=heap[n],heap[0]
        sink(heap,0,N)
    M = heap[M]
    return M

菜鸟一只，用的堆排序的方法，时间复杂度是 O(nlogn),建立堆的过程的时间复杂度是 O(n)，而对于更改堆重建过程中，对于每个元素都要下沉，
下沉 logn 次，而一共有 n 个元素，所以此时的时间复杂度为 O(nlogn)
```

发表于 2018-03-09 16:13:38

* * *

[DengJc](https://www.nowcoder.com/profile/6446069)

import heapqdef func(nums,M):    x=[nums[i] for i in range(M)]
    heapq.heapify(x)
    for n in nums[M:]:
        min=heapq.heappop(x)
        if n>min:
            heapq.heappush(x,n)
        else:
            heapq.heappush(x,min)
    return heapq.heappop(x)

发表于 2018-02-15 05:17:34

* * *

## 3

（机器学习理论）请列举生成模型与判别模型的区别

你的答案

本题知识点

数据挖掘工程师 算法工程师 唯品会 2018

讨论

[坐北朝南玄学求个 offer](https://www.nowcoder.com/profile/2268311)

生成模型是通过数据学习联合概率分布 P(x,y)，然后求出条件概率分布 P(Y|X)，作为预测的模型，即生成模型为：P(Y|X)=P(X,Y)/P(X)判别模型是通过数据直接学习判别函数 Y=f(X)或者条件概率作为预测模型。生成模型的特点：生成模型可以还原联合概率分布，而判别模型不行；生成模型的收敛速度更快，即当样本容量增大时，生成模型能更快的收敛到真实模型；当存在隐变量时，只能用生成模型。判别模型的特点：判别模型直接学习的还是判别函数或者条件概率分布，直接面对预测，往往学习的准确率要高；判别模型由于直接学习条件概率或决策函数，可以对数据进行各种程度上的抽象/定义特征并使用特征，因此可以简化学习问题。

发表于 2018-01-22 11:45:29

* * *

[编程的渣渣啊啊啊](https://www.nowcoder.com/profile/8501721)

常见的生成模型：朴素贝叶斯，隐马尔科夫，高斯混合模型，贝叶斯网常见的判别模型：LR,SVM,神经网络，KNN，条件随机场

发表于 2018-03-24 10:41:30

* * *

[一吻以谢天下](https://www.nowcoder.com/profile/245743)

判别模型通过学习样本 x 和预测值 y 之间的条件概率 p(y|x)（或者 y=f(x))）进行训练。-- NORMAL --而生成模型是通过学习 x 和 y 的联合分布律，再由概率公式转换为 p(y|x)的方式。

发表于 2018-03-03 23:38:57

* * *

## 4

（机器学习理论）请列举分类模型和回归模型的区别

你的答案

本题知识点

数据挖掘工程师 算法工程师 唯品会 2018

讨论

[一吻以谢天下](https://www.nowcoder.com/profile/245743)

分类算法和回归算法的不同可以分为几个方面：

    输出类型：分类的输出是离散值，回归的输出是连续值    最优化过程要找到的什么：分类要找到最优决策面，而回归要使得学习到的函数曲线跟真实值曲线拟合最好。    损失函数：分类常用的损失有 log loss、hinge loss 等，而回归一般是平方损失等。    评价标准：分类一般使用正确率作为评价标准，而回归一般使用决定系数 R2R2。

而分类和回归的本质上又是相同的，都是通过学习到 y=f(x)映射（或者 P(Y|X)）。所以一些模型只要做对应的修改，就可以用于分类和回归，如线性回归模型通过将 Y=WX 变为 Y=sigmoid(WX)而编程逻辑回归，同样的还有 SVR 和 SVM 等。

-- NORMAL --

发表于 2018-03-03 21:03:36

* * *

[DengJc](https://www.nowcoder.com/profile/6446069)

分类模型是预测离散的类别（给定类别），回归模型是预测一个实数值（连续数值）。

发表于 2018-02-15 05:17:21

* * *

## 5

（机器学习理论）什么是欠拟合、过拟合？避免过拟合有哪些途径？

你的答案

本题知识点

数据挖掘工程师 算法工程师 唯品会 2018

讨论

[bexvan](https://www.nowcoder.com/profile/1718713)

欠拟合：在训练集中变现得不好过拟合：在训练集中表现的好，在测试集中表现的不好。过拟合处理方法：非参数方程：借用算法方面的技巧，比如决策树中的剪枝。参数方程：参数范数惩罚，数据集增强，提前终止，dropout 等

发表于 2018-03-24 01:45:21

* * *

[六个六 666666](https://www.nowcoder.com/profile/7344416)

欠拟合：高偏差；过拟合：高方差；方法：增大数据量，正则化，Dropout

发表于 2018-02-07 09:57:59

* * *

## 6

（机器学习理论）请列举 Random Forest 和 GBDT 的区别

你的答案

本题知识点

数据挖掘工程师 算法工程师 唯品会 2018

讨论

[DengJc](https://www.nowcoder.com/profile/6446069)

Random Forest 是 bootstrap（bagging）的方法的 tree based ensemble： 即又放回的对训练数据采样，分别训练 decision tree, 最后用简单的投票方式作为最终结果。GBDT 是 boosting 的代表，每次训练都是使用所有数据，但是认为最终结果是多颗树的叠加，训练完一棵树以后，将结果的残差作为下一棵树的训练目标。在这个过程中还使用了梯度近似残差的方法。

发表于 2018-02-15 05:17:07

* * *

## 7

（机器学习理论）梯度下降法求解最优化问题的原理与步骤

你的答案

本题知识点

数据挖掘工程师 算法工程师 唯品会 2018

讨论

[DengJc](https://www.nowcoder.com/profile/6446069)

函数的梯度是函数上升的最大方向。 如果要对一个目标函数做最小化，每次只需将目标函数对各个 parameters 做偏导，得到梯度，然后用当前 parameter 加上负梯度乘以一个步长进行更新。 步长太大可能跳出局部最优点。 常用的梯度下降方法有 batch gd（使用全部数据计算梯度），SGD(对每个 sample 计算梯度)。 SGD 计算更快，并且能取得不错的效果，而且有时能跳出局部最优，去 explore 其他更优 的极值点

发表于 2018-02-15 05:16:55

* * *

[bexvan](https://www.nowcoder.com/profile/1718713)

原理：如果待求解问题是个凸优化的问题，那么只有一个最优解，就好像只有一个你是一致蚂蚁在碗里走动，因为只有一个碗底，你无论从那个初始点触发，只要玩下走，就会到达碗底。如果待求解的问题不是凸优化问题，而是多极值点的问题（神经网络就是这种情形），那么就是有多个山谷，你玩下走，能走到那个山谷，具体依赖于初始位置。步骤：一个赋值操作：新变量<—旧变量  - 学习率 * （优化函数对变量的求导）

发表于 2018-03-24 01:40:34

* * *