# 招商银行信用卡中心 2019 秋招 IT 笔试（大数据方向第二批）

## 1

在 SQL Server 中，要防止大于 100 的数被保存到 int 类型的列，可以使用

正确答案: D   你的答案: 空 (错误)

```cpp
主键约束
```

```cpp
限制约束
```

```cpp
外键约束
```

```cpp
检查约束
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[ID84848484](https://www.nowcoder.com/profile/8484574)

怎么没大佬解析一波啊

发表于 2019-04-08 22:29:04

* * *

[我不喜欢有昵称](https://www.nowcoder.com/profile/96467569)

五大约束

1.—-主键约束（Primay Key Coustraint） 唯一性，非空性

 2.—-唯一约束 （Unique Counstraint）唯一性，可以空，但只能有一个

 3.—-检查约束 (Check Counstraint) 对该列数据的范围、格式的限制（如：年龄、性别等）

 4.—-默认约束 (Default Counstraint) 该数据的默认值

 5.—-外键约束 (Foreign Key Counstraint) 需要建立两表间的关系并引用主表的列

[`blog.csdn.net/qwezhaohaihong/article/details/78326944`](https://blog.csdn.net/qwezhaohaihong/article/details/78326944)
参考文献

发表于 2021-06-04 19:44:39

* * *

[小绿叶 yo](https://www.nowcoder.com/profile/255599086)

比如设置分成绩不大于 100 alter table 选课 modify 成绩 int check(成绩 <100)

发表于 2019-10-05 18:02:49

* * *

## 2

下列对数据库事务的描述错误的是

正确答案: C   你的答案: 空 (错误)

```cpp
一致性
```

```cpp
持久性
```

```cpp
独立性
```

```cpp
原子性
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[默认昵称](https://www.nowcoder.com/profile/216758196)

数据库中实务的特性包括：原子性、隔离性、一致性、持久性

发表于 2019-08-09 00:04:50

* * *

[Enigma2018](https://www.nowcoder.com/profile/2681283)

数据库中实务 的特性包括：原子性、隔离性、一致性

发表于 2019-03-27 18:39:53

* * *

## 3

下列哪个不属于 ETL 工具

正确答案: D   你的答案: 空 (错误)

```cpp
datastage
```

```cpp
kettle
```

```cpp
sqoop
```

```cpp
tableau
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[Enigma2018](https://www.nowcoder.com/profile/2681283)

tableau 属于商业分析软件

发表于 2019-03-27 18:40:28

* * *

[牛客 563269111 号](https://www.nowcoder.com/profile/563269111)

D

发表于 2020-04-11 14:45:29

* * *

[默认昵称](https://www.nowcoder.com/profile/216758196)

tableau 是可视化工具。**ETL**，是英文 Extract-Transform-Load 的缩写，用来描述将数据从来源端经过萃取（extract）、转置（transform）、加载（load）至目的端的过程。 **ETL**一词较常用在数据仓库，但其对象并不限于数据仓库。

发表于 2019-08-09 00:06:46

* * *

## 4

OLAP 技术的核心是

正确答案: D   你的答案: 空 (错误)

```cpp
在线性
```

```cpp
对用户的快速响应
```

```cpp
互操作性
```

```cpp
多维分析
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019 数据挖掘

讨论

[LuciferLikesPython](https://www.nowcoder.com/profile/232219086)

？？

发表于 2022-02-25 08:39:48

* * *

[Enigma2018](https://www.nowcoder.com/profile/2681283)

OLTP 联机事务处理 OLAP 联机分析处理，常采用分区并行处理的方式，核心是***分析

发表于 2019-03-27 18:42:07

* * *

## 5

以下哪种说法正确

正确答案: C   你的答案: 空 (错误)

```cpp
vertica 底层存储基于 HDFS
```

```cpp
vertica 不同节点之间共享存储
```

```cpp
vertica 基于列式存储
```

```cpp
vertica 中的表可以没有 projection
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

## 6

以下哪个选项可以实现在文件 a.txt 中查找某字符串'str'

正确答案: B   你的答案: 空 (错误)

```cpp
cat a.txt grep str
```

```cpp
grep str a.txt
```

```cpp
cat a.txt | find str
```

```cpp
以上都不是
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[我不喜欢有昵称](https://www.nowcoder.com/profile/96467569)

```cpp
cat otherfilename | grep 'something'
```

发表于 2021-06-04 19:48:51

* * *

[Enigma2018](https://www.nowcoder.com/profile/2681283)

grp str a.txt

发表于 2019-03-27 18:42:47

* * *

## 7

下列关于大数据生态体系描述错误的是

正确答案: C   你的答案: 空 (错误)

```cpp
Hadoop MapReduce 只适用于批量处理数据
```

```cpp
MapReduce/Spark/Flink/Storm 均支持使用 YARN 调度资源
```

```cpp
Flink 和 Spark 既支持批量计算，也支持流式计算，两者流式计算的本质都是微批处理
```

```cpp
Spark Streaming 支持秒级延迟，其吞吐量优于 Storm
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[ZIZIBONG](https://www.nowcoder.com/profile/7901699)

Flink 是一行一行处理，而 Spark 是基于数据片集合（RDD）进行小批量处理；Flink 支持毫秒级计算，Spark 只能支持秒级计算。所以 Spark 在流式处理方面，不可避免增加一些延时。

发表于 2018-11-14 23:09:18

* * *

## 8

以下两段 python 代码输出分别为
a = 1
def fun(a):
    a = 2
fun(a)
print a 

a =[2]
def fun(a):
    a.append(1)
fun(a)
print a

正确答案: A   你的答案: 空 (错误)

```cpp
A. 第一段:1   第二段: [2,1]
```

```cpp
B. 第一段:2   第二段: [2,1]
```

```cpp
C. 第一段:1   第二段: [1]
```

```cpp
D. 第一段:2   第二段: [2]
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[零葬](https://www.nowcoder.com/profile/75718849)

基本数据类型会进行复制，而对象这样的引用类型是地址传递，并没有复制

发表于 2020-11-25 11:11:02

* * *

[current117](https://www.nowcoder.com/profile/561562297)

首先代码有点小疏漏，然后 def 函数中出现的是局部变量，只在 def 中有效，如果是赋值操作就像理解形参与主参的值传递一样；而 append 涉及到了地址引用

发表于 2020-11-25 20:43:49

* * *

## 9

若 i 为整形，下述 while 循环的执行次数为：
i = 700
while i > 1:
 print(i)
 i = i/2

正确答案: C   你的答案: 空 (错误)

```cpp
5
```

```cpp
8
```

```cpp
10
```

```cpp
12
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

## 10

下列哪些不是 HADOOP 项目的组件

正确答案: D   你的答案: 空 (错误)

```cpp
HDFS
```

```cpp
YARN
```

```cpp
MapReduce
```

```cpp
Hive
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[零葬](https://www.nowcoder.com/profile/75718849)

hadoop 项目只有三个组件：计算的 MapReduce，存储的 HDFS 和资源管理的 YARN，其余都是在此基础上对大数据生态进行的扩展

发表于 2020-11-25 11:13:03

* * *

[Enigma2018](https://www.nowcoder.com/profile/2681283)

HIve 属于 hadoop 上的程序编程语言

发表于 2019-03-27 18:45:50

* * *

[In201903052237478](https://www.nowcoder.com/profile/158537739)

D

发表于 2019-03-06 11:48:12

* * *

## 11

下列哪句话的描述正确

正确答案: C   你的答案: 空 (错误)

```cpp
Impala 查询速度快，但不适合进行大规模数据的查询
```

```cpp
在多用户同时进行查询的情况下，Impala 的查询性能急剧恶化
```

```cpp
Impala 的 SQl 语法与 Hive 一致
```

```cpp
Impala 与 Hive 使用相同的 ODBC 驱动和 JDBC 驱动
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[Enigma2018](https://www.nowcoder.com/profile/2681283)

Impala 是 Cloudera 公司主导开发的新型查询系统，它提供 SQL 语义，能查询存储在 Hadoop 的 HDFS 和 HBase 中的 PB 级大数据。已有的 Hive 系统虽然也提供了 SQL 语义，但由于 Hive 底层执行使用的是 MapReduce 引擎，仍然是一个批处理过程，难以满足查询的交互性。相比之下，Impala 的最大特点也是最大卖点就是它的快速

发表于 2019-03-27 18:46:51

* * *

## 12

下面哪个项目是 Hadoop 的接口定义语言

正确答案: C   你的答案: 空 (错误)

```cpp
Oozie
```

```cpp
Mahout
```

```cpp
Thrift
```

```cpp
Impala
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

## 13

对于 spark 参数 spark.ui.port，以下哪一个环境中的参数在运行时生效

正确答案: C   你的答案: 空 (错误)

```cpp
spark-defaults.conf 配置文件中指定
```

```cpp
spark-submit --conf spark.ui.port 提交任务时指定
```

```cpp
sparkcontext 中采用 conf.set(&quot;spark.ui.port&quot;,''14040'')指定
```

```cpp
spark-site.xml 中指定
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

## 14

Spark 中各 Stage 的 Task 数量由什么决定

正确答案: A   你的答案: 空 (错误)

```cpp
Partition
```

```cpp
Job
```

```cpp
Stage
```

```cpp
TaskScheduler
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

## 15

如果你的 umask 设置为 022，缺省的你创建的文件的权限为

正确答案: D   你的答案: 空 (错误)

```cpp
----w--w-
```

```cpp
-w--w----
```

```cpp
r-xr-x---
```

```cpp
rw-r--r-
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[加油的小蝌蚪](https://www.nowcoder.com/profile/462335611)

默认 777，umask 为 022，那么相减得 755，也就是文件夹的权限，文件的权限再要减去 111，也就是 644

发表于 2019-04-08 18:49:54

* * *

[我不喜欢有昵称](https://www.nowcoder.com/profile/96467569)

umask 可用来设定[权限掩码]。[权限掩码]是由 3 个八进制的数字所组成，将现有的存取权限减掉权限掩码后，即可产生建立文件时预设的权限。

发表于 2021-06-04 19:51:43

* * *

## 16

下列表达式正确的是

正确答案: A   你的答案: 空 (错误)

```cpp
float(‘inf’) – 1 &gt; 0
```

```cpp
float(‘inf’) &lt; float(‘inf’) + 1
```

```cpp
sum(range(1, 10, 2)) == 30
```

```cpp
sum(range(5)) == 15
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 招商银行信用卡中心 2019

讨论

[Stream201908251425680](https://www.nowcoder.com/profile/749234001)

```cpp
&lt; -> <
&gt; ->  >
```

 ```cpp
float(‘inf’)代表正负无穷 float(‘inf’) -1>0 正确
```

```cpp
float(‘inf’)< float(‘inf’) + 1 错误
```

```cpp
sum(range(1, 10, 2)) =25 因此输出 Flase
```

```cpp
sum(range(5)) =10 因此输出 Flase
``` 

发表于 2019-09-08 22:54:31

* * *

[徐付翠](https://www.nowcoder.com/profile/556882083)

有人能解释一下这个题的答案吗

发表于 2019-06-17 11:07:08

* * *

## 17

删除被从表引用的主表记录时，需修改从表的外键约束的“删除规则”为

正确答案: B C   你的答案: 空 (错误)

```cpp
不执行任何操作
```

```cpp
设置 Null
```

```cpp
级联
```

```cpp
设置默认值
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

## 18

ETL 过程包含哪些

正确答案: A B D   你的答案: 空 (错误)

```cpp
抽取
```

```cpp
装载
```

```cpp
整理
```

```cpp
转换
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[大儒哥](https://www.nowcoder.com/profile/288982644)

E（抽取），T（转换），L（加载）

发表于 2020-03-13 15:25:45

* * *

## 19

对于元组 l1 = (1, 2, 3, 4, 5, 6, 7, 8, 9)，下列哪些操作是正确的? 

正确答案: B C D   你的答案: 空 (错误)

```cpp
l1[0] = 4
```

```cpp
l1[2:-2]
```

```cpp
l1*2
```

```cpp
set(l1)
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[Enigma2018](https://www.nowcoder.com/profile/2681283)

元祖中的元素是不能被修改的

发表于 2019-03-27 18:51:38

* * *

## 20

spark 支持的 join 类型有

正确答案: A B C D   你的答案: 空 (错误)

```cpp
inner join
```

```cpp
left outer join
```

```cpp
right outer join
```

```cpp
full  outer join
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[offer 滚滚来~](https://www.nowcoder.com/profile/3284619)

Spark DataFrame 中 join 与 SQL 很像，都有 inner join, left join, right join, full join; 
那么 join 方法如何实现不同的 join 类型呢？ 
看其原型 
def join(right : DataFrame, usingColumns : Seq[String], joinType : String) : DataFrame 
def join(right : DataFrame, joinExprs : Column, joinType : String) : DataFrame 
可见，可以通过传入 String 类型的 joinType 来实现。 
joinType 可以是”inner”、“left”、“right”、“full”分别对应 inner join, left join, right join, full join，默认值是”inner”，代表内连接

发表于 2019-04-09 15:37:50

* * *

## 21

Apache Impala 具有以下哪些特性

正确答案: A C D   你的答案: 空 (错误)

```cpp
类 SQL 查询
```

```cpp
ACID
```

```cpp
可扩展性
```

```cpp
支持 UDF 函数
```

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

## 22

事实表和维度表的概念以及怎么设计？

你的答案

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

## 23

hive 表关联查询，什么情况下会发生数据倾斜，应该如何解决?

你的答案

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[牛客 817255086 号](https://www.nowcoder.com/profile/817255086)

某个 key 的数据特别多 1\. 开启 mapjoin，如果是大表和小表，那么可以在 map 端进行 join，省掉了 shuffle 嗲来数据倾斜 2\. 开启 hive.groupby.skewindata 负载均衡，先随机分发，每部分先聚合，然后再进行第二次聚合，将同一个 key 的数据进行最后的聚合

发表于 2021-09-16 15:41:03

* * *

## 24

谈谈数据库优化方面的经验看法

你的答案

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[牛客 817255086 号](https://www.nowcoder.com/profile/817255086)

1\. 加索引 2\. sql 方面多用子查询，减少数据扫描范围

发表于 2021-09-16 15:41:48

* * *

[零葬](https://www.nowcoder.com/profile/75718849)

1.多用 LIMIT

很多情况下，我们知道查询表只会有一条结果。在这种情况下，我们不妨加上 LIMIT 1，这样可以增加性能。MySQL 数据库引擎会在找到一条数据后停止搜索，而不是占据 cpu 继续往下查直到查询表中的最后一条数据为止。

2.尽量不用 ORDER BY RAND()

官方手册提及到 ORDER BY 从句里面不能使用 RAND()函数，因为这样会导致数据列被多次扫描。

3\. EXPLAIN 你的 SELECT 查询

EXPLAIN 关键字的作用是让你可以让你知道 MySQL 是如何处理你的 SQL 语句的。这可以帮你分析你的查询语句或是表结构。从根本处找出可以优化的地方，EXPLAIN 的查询结果也会告诉你，你的索引主键被如何利用的，你的数据表是如何被搜索和排序的，通过对这些信息的查看，你可以对自己的查询语句做相应的调整。

4.避免 SELECT *

我们需要哪些属性就取哪些，避免全盘接收。

5\. 为搜索字段建索引

索引并不一定就是给主键或是唯一的字段。如果在你的表中，有某个字段你总要会经常用来做搜索，那么，请为其建立索引吧。

6.利用查询缓存来优化查询

当 MySQL 开启了缓存模式（query_cache_type=1）后，mysql 会把查询语句和查询结果保存在一张 hash 表中，下一次用同样的 sql 语句查询时，mysql 会先从这张 hash 表中获取数据，如果缓存没有命中，则解析 sql 语句，查询数据库。

7.尽量不使用 NOT IN 和 like 语句操作

NOT IN 和 like“%aaa%”操作都不会使用索引，将进行全表扫描。可取的方法是 NOT IN 可以 NOT EXISTS 代替。

8.UNION-ALL 代替 UNION

如果业务上没有特殊说明，可以考虑用 UNION-ALL 替换 UNION，因为 UNION-ALL 不会过滤重复数据，所执行效率要快于 UNION,并且 UNION 可以自动排序，而 UNION-ALL 不会，这些细节往往都影响了数据库的性能。

发表于 2020-11-25 10:58:06

* * *

## 25

表 A 员工编号(INT)   组别(VARCHAR)   项目(VARCHAR) 成绩(FLOAT)    完成时间(TIMESTAMP)

  100                        A                           XM1                      200.2                2018-08-10 21:00:00

  101                        B                           XM1                     100.6                 2018-06-10 21:00:00

  102                        A                           XM1                      50.0                  2018-07-10 21:00:00

  103                        B                           XM2                     100.0                 2018-08-15 21:00:00

  101                        B                           XM2                      99.1                  2018-07-30 21:00:00

  104                        B                           XM2                      46.5                  2017-09-14 21:00:00

(注释：一个人只能在 1 个小组，一个人可参与多个项目)

 1)统计各员工的绩效信息：

  员工编号  XM1 成绩  XM1 小组排名  XM2 成绩  XM2 小组排名

 2)统计各组完成时间在 2018 年第二季度各项目平均成绩达标(>80 分)人数：

组号  XM1 达标人数 XM2 达标人数

你的答案

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[单单单单单单](https://www.nowcoder.com/profile/2181492)

1)select new1.员工编号, new1.XM1 成绩 , new1.XM1 小组排名,new2.XM2 成绩 , new2.XM2 小组排名, from(select 员工编号,成绩 as XM1 成绩,row_number() over ( order by 成绩) as XM1 小组排名 from A where 项目 = ‘XM1’)  new1join(select 员工编号,成绩 as XM2 成绩,row_number() over ( order by 成绩) as XM2 小组排名 from A where 项目 = ‘XM2’)  new2 on new1.员工编号 = new2.员工编号 2) SELECT 组别 as 组号,

    CASE WHEN 项目 = 'XM1'  and 平均成绩 > 80 THEN 人数     else 0      END AS XM1 达标人数，    CASE WHEN 项目 = 'XM2'  and 平均成绩 > 80 THEN 人数       else 0     END AS XM2 达标人数   

 FROM (select count(员工编号) as 人数 , 组别 ， 项目，avg(成绩) as 平均成绩 from A  where 完成时间 between ‘2018-04-01’ and '2018-06-30'group by 组别，项目) new

编辑于 2019-04-07 23:56:09

* * *

## 26

简述 Spark 任务提交到 yarn-cluster 上的任务运行过程。

你的答案

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[零葬](https://www.nowcoder.com/profile/75718849)

1）spark-submit 通过命令行的方式提交任务；
2）任务提交后会和 ResourceManager 通讯申请启动 ApplicationMaster；
3）随后 ResourceManager 分配 container，并在合适的 NodeManager 上启动 ApplicationMaster；
4）ApplicationMaster 启动后会创建 Driver 线程来执行用户的作业；
5）ApplicationMaster 继续向 ResourceManager 申请资源创建 Executor；
6）ResourceManager 接到资源申请后会分配 container，并在合适的 NodeManager 上启动 Executor；
7）Executor 启动之后会向 Driver 进行反向注册；
8）在 Executor 全部注册完之后 Driver 开始执行 main 函数，之后在每执行到 Action 算子时触发一个 job，并根据宽依赖开始划分 stage，然后每个 stage 生成对应的 taskSet，之后将 task 分发到各个 Executor 上执行。

发表于 2020-11-25 11:00:06

* * *

[Ricone](https://www.nowcoder.com/profile/1224729)

1.由 client 向 ResourceManager 提交请求，并上传 jar 到 HDFS 上

这期间包括四个步骤：

    a).连接到 RM

    b).从 RM 的 ASM（ApplicationsManager）中获得 metric、queue 和 resource 等信息。

    c). upload app jar and spark-assembly jar

    d).设置运行环境和 container 上下文（launch-container.sh 等脚本)

2\. ResourceManager 为该应用程序分配第一个 Container，创建 Spark ApplicationMaster（每个 SparkContext 都有一个 ApplicationMaster）

3\. NodeManager 启动 ApplicationMaster，并向 ResourceManager 注册

4\. ApplicationMaster 从 HDFS 中找到 jar 文件，启动 SparkContext、DAGscheduler 和 YARN Cluster Scheduler

5\. ApplicationMaster 向 ResourceManager 注册申请 container 资源

6\. ResourceManager 通知 NodeManager 分配 Container（每个 container 对应一个 executor）

7\. Spark ApplicationMaster 直接和 container（executor）进行交互，完成这个分布式任务。

发表于 2019-09-08 23:30:53

* * *

## 27

简述 python 是如何进行内存管理的。

你的答案

本题知识点

算法工程师 招商银行信用卡中心 大数据开发工程师 2019

讨论

[零葬](https://www.nowcoder.com/profile/75718849)

python 内部使用引用计数，来保持追踪内存中的对象，Python 内部记录了对象有多少个引用，即引用计数，当对象被创建时就创建了一个引用计数，当对象不再需要时，这个对象的引用计数为 0 时，它被垃圾回收。所有这些都是自动完成，不需要像 C 一样，人工干预，从而提高了程序员的效率和程序的健壮性。 

发表于 2020-11-25 11:08:49

* * *

[余生与你后会无期](https://www.nowcoder.com/profile/433115155)

python 采用"引用计数"和"垃圾回收"两种机制来管理内存。
引用计数通过记录对象被引用的次数来管理对象。
对对象的引用都会使得引用计数加 1，移除对对象的引用，引用计数则会减 1，
当引用计数减为 0 时，对象所占的内存就会被释放掉。
引用计数可以高效的管理对象的分配和释放，但是有一个缺点，就是无法释放引用循环的对象
这个时候就需要垃圾回收机制(garbage collection)，来回收循环应用的对象。
垃圾回收机制会根据内存的分配和释放情况的而被调用，

发表于 2019-03-08 15:35:04

* * *